{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jydSMVmR99ZP",
        "outputId": "40b46a98-fc7c-4d40-bc91-a4281576afc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TFYMyJM0APJA",
        "outputId": "08398be8-34f9-44f7-f78d-b1f951c2d17e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.24.0-py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.3/312.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "ej8K2n7cAU7g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from dotenv import load_dotenv\n"
      ],
      "metadata": {
        "id": "QBXsV29DAYbN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "99V0aaDWAjKr"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "yJQK6-ihCcSb"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QUESTION 4"
      ],
      "metadata": {
        "id": "2c2a5DNwLlb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = client.chat.completions.create(\n",
        "    model = 'gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system', \"content\":\"Translate the following sentence into Spanish concisely\"},\n",
        "        {'role':'user',\"content\" :'what time is the meeting'}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =30,\n",
        "    top_p =1\n",
        "\n",
        ")\n",
        "\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vxz3akVAu7H",
        "outputId": "c94efcfd-2b7a-4a43-9610-331620030b4e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-9Jm76AphNoS2eabkTPEZ7btTuhVUa', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='¿A qué hora es la reunión?', role='assistant', function_call=None, tool_calls=None))], created=1714500208, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=9, prompt_tokens=25, total_tokens=34))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onFRRaGhLRSh",
        "outputId": "53915172-5b32-4674-e1af-78524bd1f0a4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿A qué hora es la reunión?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# question 7"
      ],
      "metadata": {
        "id": "xotj180qLgn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response2 = client.chat.completions.create(\n",
        "    model ='gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system','content':'Explain the technical concept briefly enough to fit as an MCQ option.'},\n",
        "        {'role':'user',\"content\" :'What is cloud computing?'}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =30,\n",
        "    top_p =1\n",
        ")\n",
        "response2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtNY56noB2XV",
        "outputId": "c3340d5e-b3ce-414a-d99a-9dcfb5783b6e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-9Jm7Z5B2sNNSQGAmaGTlxO3pxsS6d', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='Cloud computing is a technology that allows users to access and store data, applications, and services over the internet instead of on a local server or personal computer', role='assistant', function_call=None, tool_calls=None))], created=1714500237, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=30, prompt_tokens=31, total_tokens=61))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response2.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNXjPDUHEWL2",
        "outputId": "c9296d2a-2334-49ad-cc5f-48896a461169"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloud computing is a technology that allows users to access and store data, applications, and services over the internet instead of on a local server or personal computer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vyBi5O-6Eut0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pHYA2HR_E48a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# question 9"
      ],
      "metadata": {
        "id": "dbZtKh4HE5lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response3 = client.chat.completions.create(\n",
        "    model ='gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system','content':'Classify the following text’s tone in a brief form that could fit as an MCQ option'},\n",
        "        {'role':'user',\"content\" :'The meeting was cancelled due to unforeseen circumstances.'}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =30,\n",
        "    top_p =1\n",
        ")\n",
        "response3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNXbpbUEE7SE",
        "outputId": "3db0e4b6-a42c-4c8e-a52d-c9d7707cc63c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-9Jm9LGb8d7zlI9aDmXbKLoZbkatfg', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Neutral', role='assistant', function_call=None, tool_calls=None))], created=1714500347, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=1, prompt_tokens=40, total_tokens=41))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response3.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egdNkflsFVp4",
        "outputId": "a7079b6e-ec87-4180-9157-3e4a977bc60b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "24FjKe0zGYan"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qqkjr1ZxFYGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QUESTION 11"
      ],
      "metadata": {
        "id": "4gNehXpOFkb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response4 = client.chat.completions.create(\n",
        "    model ='gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system','content':'you are a knowledgeable assistant. A user will ask a question and you should provide a clear and concise answer briefly enough to fit as an MCQ option'},\n",
        "        {'role':'user',\"content\" :'what causes the Northern Lights?'}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =150,\n",
        "    top_p =1\n",
        ")\n",
        "response4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzYTkeMnFmi0",
        "outputId": "dc3ec87a-e29b-4ca1-8e77-a4e1fdcf3da3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-9Jm9aKGEzT5WEumQ7TD2FVI5yLVAZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Solar wind interacting with the Earth's magnetic field causes the Northern Lights.\", role='assistant', function_call=None, tool_calls=None))], created=1714500362, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=14, prompt_tokens=47, total_tokens=61))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response4.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bFTIphCGIDL",
        "outputId": "6a11e330-bf58-497c-eeba-4d3e6c3648f7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solar wind interacting with the Earth's magnetic field causes the Northern Lights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m5u1tAOkGK5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QUESTION 12"
      ],
      "metadata": {
        "id": "BUDaZpoaGZ4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response5 = client.chat.completions.create(\n",
        "    model ='gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system','content':'Provide a concise fact about the event in history mentioned by the user briefly enough to fit as an MCQ option.'},\n",
        "        {'role':'user',\"content\" :'What was the main cause of the Americam civil war?'}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =40,\n",
        "    top_p =1\n",
        ")\n",
        "response5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUcvzkV4Gdbt",
        "outputId": "f62f0492-09e2-4b9c-e772-02e98947c67d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-9Jm9jEpdOLelNFIllpxN6rnJY1vJo', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The main cause of the American Civil War was the issue of slavery.', role='assistant', function_call=None, tool_calls=None))], created=1714500371, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=14, prompt_tokens=46, total_tokens=60))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response5.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G35UigxGxg-",
        "outputId": "fc968ca8-459f-483f-c3a8-e94d21d028ff"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The main cause of the American Civil War was the issue of slavery.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QUESTION 13"
      ],
      "metadata": {
        "id": "zeRUclF5G7L1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response6 = client.chat.completions.create(\n",
        "    model ='gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system','content':'Provide a brief, accurate answer to the user’s question that can be used as an MCQ option.'},\n",
        "        {'role':'user',\"content\" :'Who is known as the father of computer science?'}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =30,\n",
        "    top_p =1\n",
        ")\n",
        "response6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfY3LJW_Gx--",
        "outputId": "18344b6f-9045-4102-f552-29f50ffe57ba"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-9JmA8nePsQMmRtJfcixgzPZpzrp7B', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Alan Turing', role='assistant', function_call=None, tool_calls=None))], created=1714500396, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=2, prompt_tokens=42, total_tokens=44))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response6.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OpFf01IHKvp",
        "outputId": "4904ae30-48a5-4749-cc31-b4fd9f1f7c7b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alan Turing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xIz31gXLHM_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 14"
      ],
      "metadata": {
        "id": "krfx4v1JHVLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response7 = client.chat.completions.create(\n",
        "    model ='gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system','content':\"you are to summarize the rpovided text into a concise form, maintaining the key points and context, briefly enough toi fit as an MCQ option\"},\n",
        "        {'role':'user',\"content\" :\"the economy has been growing steadily over the past few quarters, driven by increases in consumer spending and substantial investments in renewable energy infrastructur. unemployment rates have also fallen to record lows as new industries are creating more jobs\"}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =100,\n",
        "    top_p =1\n",
        ")\n",
        "response7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8NZ1I3qHYup",
        "outputId": "b539352e-3dbd-4ffc-e7e0-873d15c77c2d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-9JmALqBuQGTRXyixJHQ8gyMXZDmpd', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The economy has been growing steadily due to increased consumer spending and investments in renewable energy infrastructure. Unemployment rates have decreased to record lows as new industries are generating more jobs.', role='assistant', function_call=None, tool_calls=None))], created=1714500409, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=34, prompt_tokens=84, total_tokens=118))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response7.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2W8JSEZIRVc",
        "outputId": "a78206e9-c919-4ca8-e4ab-825b3d91bb2d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The economy has been growing steadily due to increased consumer spending and investments in renewable energy infrastructure. Unemployment rates have decreased to record lows as new industries are generating more jobs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IiJxGpYSIT6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 15"
      ],
      "metadata": {
        "id": "s-V21NVKIch_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response8 = client.chat.completions.create(\n",
        "    model ='gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system','content':\"you are to classify the provided text\"},\n",
        "        {'role':'user',\"content\" :\"I had an awful experience at the restaurant. The food was bland and the service was slow.\"}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =16,\n",
        "    top_p =1\n",
        ")\n",
        "response8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADy_pS4yIf8L",
        "outputId": "ad2f0b6f-34e5-4039-9a22-155d1464470e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-9JmAdLya1nzIV47YFfacjcEoGUM4J', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Sentiment: Negative', role='assistant', function_call=None, tool_calls=None))], created=1714500427, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=4, prompt_tokens=37, total_tokens=41))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response8.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPYkk0FJIyZn",
        "outputId": "6db875ea-b9e7-482b-e12d-e72e6438031f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "31gsklDUJH0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fFYOsGFEJIHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 16"
      ],
      "metadata": {
        "id": "LbQTY031JpT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response9 = client.chat.completions.create(\n",
        "    model ='gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system','content':\"summarize the following text into a concise phrase suitable for an MCQ answer option\"},\n",
        "        {'role':'user',\"content\" :\"The internet was developed to help researchers communicate and share computing resources. Today, it connects millions of people and devices across the globe.\"}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =30,\n",
        "    top_p =1\n",
        ")\n",
        "response9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crvcXKp6I03x",
        "outputId": "e425d0f9-bf08-40b5-cabb-6a77a9731d51"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-9JmAkL24SBpH91uG3PhpPGdZJUNUO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The internet was developed for research communication and resource sharing, now connecting millions globally.', role='assistant', function_call=None, tool_calls=None))], created=1714500434, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=16, prompt_tokens=54, total_tokens=70))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response9.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUiCRC_VJa6m",
        "outputId": "417237e2-80b6-49e1-d067-b9b8d2f22efc"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The internet was developed for research communication and resource sharing, now connecting millions globally.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I5h7YxRUJcZu"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_hzSp3KeJtSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w6_ZgUxJJtgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qVI2Epy8Jti-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# question 18"
      ],
      "metadata": {
        "id": "mJiMuAs9JuAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response10 = client.chat.completions.create(\n",
        "    model ='gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system','content':\"you will be provided with a sentence in english and your task is to translate it into german\"},\n",
        "        {'role':'user',\"content\" :\"How do you say 'I love to travel' in German?\"}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =64,\n",
        "    top_p =1\n",
        ")\n",
        "response10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpVQjhOWJw7o",
        "outputId": "06995789-c489-42ae-d2c3-b8149df5837f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-9JmB0ibrnPy8hK3ZCl4zRxj2OIztH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Ich liebe es zu reisen.\"', role='assistant', function_call=None, tool_calls=None))], created=1714500450, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=8, prompt_tokens=42, total_tokens=50))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response10.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSd1EyI_KLdQ",
        "outputId": "2854865c-3b19-4d8a-c91b-23e4df70761b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Ich liebe es zu reisen.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QlTqf6YxKM7g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}